apiVersion: v1
data:
  autohttps: autohttps
  autohttps-serviceaccount: autohttps
  checksum_hook-image-puller: b22db046307e86bd962a68bbec1eab0be14384d325459493736d0bd2528b0026
  continuous-image-puller: continuous-image-puller
  fullname: ""
  fullname-dash: ""
  hook-image-awaiter: hook-image-awaiter
  hook-image-awaiter-serviceaccount: hook-image-awaiter
  hook-image-puller: hook-image-puller
  hub: hub
  hub-existing-secret: ""
  hub-existing-secret-or-default: hub
  hub-pvc: hub-db-dir
  hub-serviceaccount: hub
  image-pull-secret: image-pull-secret
  image-puller-priority: jupyterhub-image-puller-priority
  ingress: jupyterhub
  jupyterhub_config.py: |
    import glob
    import os
    import re
    import sys
    from binascii import a2b_hex

    from jupyterhub.utils import url_path_join
    from kubernetes_asyncio import client
    from tornado.httpclient import AsyncHTTPClient

    c.JupyterHub.spawner_class = "kubespawner.KubeSpawner"

    # Connect to a proxy running in a different pod. Note that *_SERVICE_*
    # environment variables are set by Kubernetes for Services
    c.ConfigurableHTTPProxy.api_url = 'http:/{}:{}'.format(os.environ['PROXY_API_SERVICE_HOST'],
    int(os.environ['PROXY_API_SERVICE_PORT']))
    c.ConfigurableHTTPProxy.should_start = False

    # Do not shut down user pods when hub is restarted
    c.JupyterHub.cleanup_servers = False

    # Check that the proxy has routes appropriately setup
    c.JupyterHub.last_activity_interval = 120

    c.Spawner.http_timeout = 120
    c.Spawner.start_timeout = 120


    # configure the hub db connection
    #db_type = get_config("hub.db.type")
    #if db_type == "sqlite-pvc":
    #    c.JupyterHub.db_url = "sqlite:///jupyterhub.sqlite"
    #elif db_type == "sqlite-memory":
    #    c.JupyterHub.db_url = "sqlite://"
    #else:
    #    set_config_if_not_none(c.JupyterHub, "db_url", "hub.db.url")

    # hub_bind_url configures what the JupyterHub process within the hub pod's
    # container should listen to.
    hub_container_port = 8081
    #c.JupyterHub.hub_bind_url = f"http://:{hub_container_port}"

    c.JupyterHub.ip = os.environ['PROXY_PUBLIC_SERVICE_HOST']
    c.JupyterHub.port = int(os.environ['PROXY_PUBLIC_SERVICE_PORT'])

    # # the hub should listen on all interfaces, so the proxy can access it
    c.JupyterHub.hub_ip = '0.0.0.0'

    #c.KubeSpawner.image = "jupyter/pyspark-notebook:latest"
    #c.KubeSpawner.image="aidaph/pyspark-notebook:latest"
    c.KubeSpawner.image="jupyterhub/k8s-singleuser-sample:2.0.0"

    c.KubeSpawner.service_account = "hub"

    # Mount volume for storage
    pvc_name_template = 'claim-{username}'
    c.KubeSpawner.pvc_name_template = pvc_name_template
    volume_name_template = 'volume-{username}'

    c.KubeSpawner.storage_pvc_ensure = True
    c.KubeSpawner.storage_class = 'cinder-csi'
    c.KubeSpawner.storage_access_modes = ['ReadWriteOnce']
    c.KubeSpawner.storage_capacity = '200Mi'

    # Add volumes to singleuser pods
    c.KubeSpawner.volumes = [
        {
            'name': volume_name_template,
            'persistentVolumeClaim': {
                'claimName': pvc_name_template
            }
        }
    ]
    c.KubeSpawner.volume_mounts = [
        {
            'mountPath': '/home/jovyan',
            'name': volume_name_template
        }
    ]

    # # Gives spawned containers access to the API of the hub
    c.JupyterHub.hub_connect_ip = os.environ['HUB_SERVICE_HOST']
    #c.JupyterHub.hub_connect_port = int(os.environ['HUB_SERVICE_PORT'])
    host = os.environ['HUB_SERVICE_HOST']
    port = int(os.environ['HUB_SERVICE_PORT'])
    #c.Jupyterhub.hub_connect_url = 'http://hub:8081'
    #c.JupyterHub.hub_connect_url = (
    #    f'http://{hub_connect_ip}:{os.environ["HUB_SERVICE_PORT"]}'
    #)
    

    c.JupyterHub.authenticator_class = 'jupyterhub.auth.DummyAuthenticator'
    c.DummyAuthenticator.password = "DataLab2023"

    c.KubeSpawner.fs_gid = 100
    c.KubeSpawner.gid = 100

    c.KubeSpawner.args = ['--allow-root']
    c.Spawner.cmd = ['jupyterhub-singleuser']
    def notebook_dir_hook(spawner):
        spawner.environment = {'NB_USER':spawner.user.name, 'NB_UID':'1500', 'JUPYTER_GATEWAY_URL': 'http://enterprise-gateway.enterprise-gateway.svc.cluster.local:8888'}
    c.Spawner.pre_spawn_hook = notebook_dir_hook

    # define our service
    c.JupyterHub.services = [
        {
            "name": "service-admin",
            "api_token": "030ec3465d73cd033e8a7cdc608eedf6c33be132add96155e34e59127361ff5c",
        },
    ]


    c.JupyterHub.load_roles = [
        {
            "name": "service-role",
            "scopes": [
                "admin:users",  # manage servers
                "admin:servers",  # access servers themselves
                "read:users",
                "list:users",
                "read:servers",
            ],
    #        "users": ["aidaph"],
    #        # assign role to our 'launcher' service
            "services":[
                "service-admin",
            ],
        }
    ]

  priority: jupyterhub-default-priority
  proxy: proxy
  proxy-api: proxy-api
  proxy-http: proxy-http
  proxy-public: proxy-public
  proxy-public-manual-tls: proxy-public-manual-tls
  proxy-public-tls: proxy-public-tls-acme
  singleuser: singleuser
  user-placeholder: user-placeholder
  user-placeholder-priority: jupyterhub-user-placeholder-priority
  user-scheduler: jupyterhub-user-scheduler
  user-scheduler-deploy: user-scheduler
  user-scheduler-lock: user-scheduler-lock
  user-scheduler-serviceaccount: user-scheduler
  z2jh.py: |
    """
    Utility methods for use in jupyterhub_config.py and dynamic subconfigs.

    Methods here can be imported by extraConfig in values.yaml
    """
    import os
    from collections.abc import Mapping
    from functools import lru_cache

    import yaml


    # memoize so we only load config once
    @lru_cache
    def _load_config():
        """Load the Helm chart configuration used to render the Helm templates of
        the chart from a mounted k8s Secret, and merge in values from an optionally
        mounted secret (hub.existingSecret)."""

        cfg = {}
        for source in ("secret/values.yaml", "existing-secret/values.yaml"):
            path = f"/usr/local/etc/jupyterhub/{source}"
            if os.path.exists(path):
                print(f"Loading {path}")
                with open(path) as f:
                    values = yaml.safe_load(f)
                cfg = _merge_dictionaries(cfg, values)
            else:
                print(f"No config at {path}")
        return cfg


    @lru_cache
    def _get_config_value(key):
        """Load value from the k8s ConfigMap given a key."""

        path = f"/usr/local/etc/jupyterhub/config/{key}"
        if os.path.exists(path):
            with open(path) as f:
                return f.read()
        else:
            raise Exception(f"{path} not found!")


    @lru_cache
    def get_secret_value(key, default="never-explicitly-set"):
        """Load value from the user managed k8s Secret or the default k8s Secret
        given a key."""

        for source in ("existing-secret", "secret"):
            path = f"/usr/local/etc/jupyterhub/{source}/{key}"
            if os.path.exists(path):
                with open(path) as f:
                    return f.read()
        if default != "never-explicitly-set":
            return default
        raise Exception(f"{key} not found in either k8s Secret!")


    def get_name(name):
        """Returns the fullname of a resource given its short name"""
        return _get_config_value(name)


    def get_name_env(name, suffix=""):
        """Returns the fullname of a resource given its short name along with a
        suffix, converted to uppercase with dashes replaced with underscores. This
        is useful to reference named services associated environment variables, such
        as PROXY_PUBLIC_SERVICE_PORT."""
        env_key = _get_config_value(name) + suffix
        env_key = env_key.upper().replace("-", "_")
        return os.environ[env_key]


    def _merge_dictionaries(a, b):
        """Merge two dictionaries recursively.

        Simplified From https://stackoverflow.com/a/7205107
        """
        merged = a.copy()
        for key in b:
            if key in a:
                if isinstance(a[key], Mapping) and isinstance(b[key], Mapping):
                    merged[key] = _merge_dictionaries(a[key], b[key])
                else:
                    merged[key] = b[key]
            else:
                merged[key] = b[key]
        return merged


    def get_config(key, default=None):
        """
        Find a config item of a given name & return it

        Parses everything as YAML, so lists and dicts are available too

        get_config("a.b.c") returns config['a']['b']['c']
        """
        value = _load_config()
        # resolve path in yaml
        for level in key.split("."):
            if not isinstance(value, dict):
                # a parent is a scalar or null,
                # can't resolve full path
                return default
            if level not in value:
                return default
            else:
                value = value[level]
        return value


    def set_config_if_not_none(cparent, name, key):
        """
        Find a config item of a given name, set the corresponding Jupyter
        configuration item if not None
        """
        data = get_config(key)
        if data is not None:
            setattr(cparent, name, data)
kind: ConfigMap
metadata:
  labels:
    app: jupyterhub
    chart: jupyterhub-2.0.0
    component: hub
    release: jupyterhub
  name: hub
